# Validation Report: Notebook Solutions vs. Dynamic Games Theory

## Overview
This report validates the notebook implementation (`dg.ipynb`) against:
1. The theoretical framework in `Dynamic_Games.txt` (lecture notes)
2. The homework specification in `HW_2_Ackerberg_BBL.txt`
3. The comprehensive treatment in `Chapter_4_Dynamic_Games.txt` (Handbook chapter)

---

## 1. Framework Consistency ✓

### Model Structure
- **Notebook**: Implements dynamic entry/exit game with Cournot competition
- **Lecture Notes**: Describes general framework for dynamic games with entry/exit and investment
- **Status**: ✓ Consistent - notebook implements simplified version (entry/exit only, no investment)

### State Space
- **Notebook**: `N_t ∈ {0,1,2,3,4,5}`, `x_t ∈ {-5,0,5}` → 18 states
- **Lecture Notes**: General framework with `s_{it} ∈ S` (quality levels)
- **Status**: ✓ Consistent - notebook uses number of firms as state (simplified)

---

## 2. Value Functions ✓

### Incumbent Value Function
**Notebook**:
```python
V(N_t, x_t, μ_it) = max{μ_it, π(N_t, x_t) + 0.9E[V(N_{t+1}, x_{t+1}, μ_{it+1})|N_t, x_t, d_it=1]}
```

**Lecture Notes** (lines 84-86):
```
V(s_it, s_{-it}; θ) = E[max{π + β(φ + φ_it), max_a{π - ca_it + ε_it + βE[V(s_{it+1}, s_{-it+1})]}}]
```

**Status**: ✓ Consistent - notebook uses simplified version (no investment decision, exit value is μ_it)

### Entrant Value Function
**Notebook**:
```python
V^E(N_t, x_t, γ_it) = max{0, -γ_it + 0.9E[V(N_{t+1}, x_{t+1}, μ_{it+1})|N_t, x_t, e_it=1]}
```

**Lecture Notes** (lines 119-134):
```
V^ent(s_t) = E[max{0, -κ + ε^ent_t + βE[V(s̄, s_{-it+1})|s_t]}]
```

**Status**: ✓ Consistent - notebook matches structure

---

## 3. Markov Perfect Equilibrium ✓

### Cutoff Strategies
**Notebook**: Implements cutoff equilibrium:
- Exit if `μ_it > μ(N_t, x_t)`
- Enter if `γ_it ≤ γ(N_t, x_t)`

**Lecture Notes** (lines 142-152):
- Defines MPE with policy functions `d(s_it, s_{-it}, φ_it, ε_it)`
- Notes integration over unobservable shocks to get CCPs

**Status**: ✓ Consistent - cutoff form is valid MPE

### Rational Expectations
**Notebook**: Implements belief consistency through transition probabilities `Pr(N_{t+1}|N_t, x_t, d_it=1)`

**Lecture Notes** (lines 175-190):
- MPE requires: (1) policies solve dynamic problem given beliefs, (2) beliefs generated by equilibrium policies

**Status**: ✓ Consistent - algorithm enforces rational expectations

---

## 4. Equilibrium Solution Algorithm ✓

### Iterative Procedure
**Notebook** (Cell 10):
1. Guess cutoffs and V̄
2. Compute transition probabilities
3. Compute continuation values Ψ₁, Ψ₂
4. Update cutoffs
5. Update V̄ using truncated normal
6. Iterate until convergence

**Lecture Notes** (lines 205-235):
1. Guess value functions and beliefs
2. Iterate Bellman equation (holding beliefs fixed)
3. Update beliefs from policies
4. Repeat

**Status**: ✓ Consistent - notebook implements homework-specific algorithm which matches general framework

### Convergence Issues
**Notebook**: Tests for multiple equilibria (Question 5), uses damping for stability

**Lecture Notes** (lines 237-260):
- Notes convergence not guaranteed
- Mentions multiplicity problem
- Suggests trying multiple initial guesses

**Status**: ✓ Consistent - notebook addresses these issues

---

## 5. V̄ Computation ✓

### Formula Implementation
**Notebook** (lines 543-558):
```python
z = (thresh - self.mu) / self.sigma_mu
prob_stay = norm.cdf(z)  # Φ(z) where z = (μ' - μ)/σ_μ
mills = norm.pdf(z) / (1 - norm.cdf(z))
E_mu_exit = self.mu + self.sigma_mu * mills
V_new = prob_stay * thresh + (1 - prob_stay) * E_mu_exit
```

**Homework** (lines 236-256):
```
V'(N_t, x_t) = [1 - Φ((μ' - μ)/σ_μ)] * [μ + σ_μ * φ(z)/(1-Φ(z))] 
               + Φ((μ' - μ)/σ_μ) * μ'(N_t, x_t)
```

**Verification**:
- `prob_stay = Φ(z)` where `z = (μ' - μ)/σ_μ` ✓
- `E_mu_exit = μ + σ_μ * φ(z)/(1-Φ(z))` (Mills ratio) ✓
- `V_new = Φ(z) * μ' + [1-Φ(z)] * E_mu_exit` ✓

**Status**: ✓ **CORRECT** - formula matches homework specification exactly

---

## 6. BBL Estimation Approach ✓

### Step 1: Estimate CCPs
**Notebook** (Cell 21):
- Estimates `d̂(N_t, x_t)` = probability incumbent stays
- Estimates `ê(N_t, x_t)` = probability entrant enters
- Uses frequency simulator (proportion of observations)

**Lecture Notes** (lines 311-326):
- "Estimate nonparametrically: d̂(s_it, s_{-it}), ê(s_t)"
- "If sit is discrete we can do this for every possible state value"

**Status**: ✓ Consistent - matches BBL Step 1

### Step 2: Forward Simulation
**Notebook** (Cell 23):
- Forward simulates PDV using estimated CCPs
- Simulates actions of all firms (entrants, other incumbents, Firm 1)
- Uses fixed random draws (critical for estimation stability)

**Lecture Notes** (lines 347-368):
- "BBL: If you have continuous state space simulate value functions"
- "Just like in HMSS, but we have to simulate the actions of all firms"
- Steps 1-8 match forward simulation logic

**Status**: ✓ Consistent - implementation matches lecture description

### Fixed Random Draws
**Notebook** (Cell 23, `setup_fixed_draws`):
- Pre-generates N(0,1) draws
- Transforms via `μ + σ_μ * draw` (holds underlying draws constant)

**Homework** (lines 313-315):
- "hold the underlying N(0,1) draws constant as the parameters change"

**Status**: ✓ **CORRECT** - critical for estimation stability

---

## 7. Forward Simulation Logic ✓

### Incumbent Simulation
**Notebook** (`forward_simulate_incumbent`):
1. Conditions on Firm 1 staying in current period
2. Simulates exit decisions for OTHER incumbents
3. Simulates entry decision
4. Simulates Firm 1's future exit decision
5. Records discounted profits + exit value if exits

**Homework** (lines 303-333):
- "forward simulate the PDV of one of the incumbents conditional on that firm deciding not to exit in the initial period"
- "simulate 1) decisions of potential entrants, 2) decisions of firms other than Firm 1, 3) decisions of Firm 1 in the future"

**Status**: ✓ **CORRECT** - matches homework specification

### Decision Rule Implementation
**Notebook**:
```python
prob_mu = norm.cdf((mu_it - mu) / sigma_mu)
if prob_mu <= self.d_hat.get((N_t, x_t), 0.5):
    # Firm stays
```

**Homework** (lines 318-322):
```
Φ((μ_it - μ)/σ_μ) ≤ d̂(N_t, x_t)  →  firm stays
```

**Status**: ✓ **CORRECT** - matches homework formula

### Entrant Simulation
**Notebook** (`forward_simulate_entrant`):
- Simulates PDV net of entry cost (doesn't subtract γ_it)
- Entrant becomes incumbent next period

**Homework** (lines 374-377):
- "expected PDV of a potential entrant entering, net of the entry cost γ_it (by 'net of the entry cost γ_it' I mean that you should not add the -γ_it for the entering period)"

**Status**: ✓ **CORRECT** - correctly implements "net of entry cost"

---

## 8. Objective Function ✓

### Minimum Distance Criterion
**Notebook** (`objective_function`):
```python
obj += (pred_prob - actual_prob) ** 2
where pred_prob = Φ((Λ - μ)/σ_μ) for incumbents
      pred_prob = Φ((Λ^E - γ)/σ_γ) for entrants
```

**Homework** (lines 411-447):
```
min Σ_{N_t=1}^5 Σ_{x_t} [Φ((Λ - μ)/σ_μ) - d̂(N_t, x_t)]² 
  + Σ_{N_t=0}^4 Σ_{x_t} [Φ((Λ^E - γ)/σ_γ) - ê(N_t, x_t)]²
```

**Status**: ✓ **CORRECT** - matches homework specification exactly

---

## 9. Theoretical Concepts ✓

### V̄ Interpretation
**Notebook** (Cell 6):
- Describes V̄ as "ex-ante expected value before observing private shock"
- Connects to Rust's integrated value function
- Explains truncated normal formula

**Lecture Notes** (lines 131-134):
- Defines V̄(N_t, x_t) = ∫ V(N_t, x_t, μ_it) p(dμ_it)

**Status**: ✓ Consistent - interpretation matches theory

### Cutoff Equilibrium Intuition
**Notebook** (Cell 5):
- Explains monotonicity, binary decisions, additively separable payoffs

**Lecture Notes**: Notes that cutoff strategies are natural in this setup

**Status**: ✓ Consistent - explanation is correct

---

## 10. Potential Issues & Recommendations

### Minor Issues
1. **Damping Parameter**: Notebook uses `damping=0.5` which is reasonable but not specified in homework. This is a computational stability enhancement.

2. **Convergence Tolerance**: Uses `tol=1e-8` which is stricter than necessary but fine.

3. **Simulation Horizon**: Uses `max_periods=100` for forward simulation, which is reasonable given β=0.9.

### Recommendations
1. ✓ **Fixed Random Draws**: Correctly implemented - critical for estimation
2. ✓ **CCP Estimation**: Uses frequency simulator as specified
3. ✓ **Forward Simulation**: Correctly conditions on Firm 1 staying
4. ✓ **Objective Function**: Matches homework specification

---

## Summary

### Overall Assessment: ✓ **VALIDATED**

The notebook implementation is **theoretically sound** and **correctly implements**:

1. ✓ Dynamic entry/exit game framework
2. ✓ Markov Perfect Equilibrium with cutoff strategies
3. ✓ Equilibrium solution algorithm (matches homework specification)
4. ✓ V̄ computation using truncated normal (matches homework formula exactly)
5. ✓ BBL two-step estimation approach
6. ✓ Forward simulation logic (matches homework specification)
7. ✓ Minimum distance objective function (matches homework specification)
8. ✓ Fixed random draws for estimation stability

### Key Strengths
- Correct implementation of truncated normal formula for V̄
- Proper conditioning in forward simulation (Firm 1 stays in initial period)
- Fixed random draws for estimation stability
- Tests for multiple equilibria
- Matches homework specifications exactly

### No Critical Issues Found
All major theoretical and implementation aspects align with the Dynamic Games framework and homework requirements.

---

## 11. Validation Against Chapter 4 (Handbook) ✓

### 11.1 Markov Perfect Nash Equilibrium Definition ✓

**Chapter 4** (Section 2.2.1, lines 315-321):
- Defines MPNE as strategies that are functions only of payoff-relevant state variables
- Each firm maximizes value given strategies of other players
- Value function solves Bellman equation: `V_i^α(x_t) = max_{a_it} {π_i^α(a_it, x_t) + β_i ∫ V_i^α(x_{t+1}) dF_{x,i}^α(x_{t+1}|x_t, a_it)}`

**Notebook**:
- Implements cutoff strategies based on public state `(N_t, x_t)` only
- Value functions solve Bellman equation with continuation values

**Status**: ✓ **CORRECT** - matches MPNE definition

### 11.2 Incomplete Information and CCPs ✓

**Chapter 4** (Section 2.2.3, lines 366-391):
- Introduces private information shocks `ε_it` to ensure equilibrium existence
- Defines Conditional Choice Probabilities: `P_i(a_it|x_t) = ∫ 1{α_i(x_t, ε_it) = a_it} dF_ε(ε_it)`
- CCPs represent expected behavior from perspective of other firms

**Notebook**:
- Uses private shocks: `μ_it ~ N(μ, σ_μ²)` for exit, `γ_it ~ N(γ, σ_γ²)` for entry
- Estimates CCPs: `d̂(N_t, x_t)` and `ê(N_t, x_t)` from data
- CCPs represent probability of staying/entering conditional on public state

**Status**: ✓ **CORRECT** - matches incomplete information framework

### 11.3 Integrated Value Function ✓

**Chapter 4** (Section 2.2.3, lines 462-481):
- Defines integrated value function `V_i^P(x_t)` that integrates over private shocks
- Solves: `V_i^P(x_t) = ∫ max_{a_i} {π_i^P(a_i, x_t, ε_it) + β_i ∫ V_i^P(x_{t+1}) dF_{x,i}^P(x_{t+1}|x_t, a_i)} dF_ε(ε_it)`

**Notebook**:
- Implements `V̄(N_t, x_t) = ∫ V(N_t, x_t, μ_it) p(dμ_it)`
- Uses truncated normal formula to compute expectation over private shocks

**Status**: ✓ **CORRECT** - matches integrated value function concept

### 11.4 BBL Forward Simulation Method ✓

**Chapter 4** (Section 3.3.3, lines 1950-1990):
- Describes forward simulation: "Given x_t and a_it, use estimated transition probability to generate x_{t+1}, use estimated CCP to generate a_{i,t+1}, proceed sequentially"
- Monte Carlo approximation: `ĥ_{i,R}^P(a_it, x_t) = h(a_it, x_t) + (1/R) Σ_r Σ_s β_i^s h(a_{i,t+s}^{(r)}, x_{t+s}^{(r)})`
- Notes that simulation error doesn't generate first-order asymptotic bias (McFadden, 1989)

**Notebook**:
- Forward simulates using estimated CCPs `d̂` and `ê`
- Generates paths of states and actions sequentially
- Averages over R=50 simulations to compute Λ values
- Uses fixed random draws to ensure smooth objective function

**Status**: ✓ **CORRECT** - matches BBL forward simulation methodology

### 11.5 BBL Moment Inequalities ✓

**Chapter 4** (Section 3.3.3, lines 2001-2071):
- BBL uses moment inequalities: `W_{it}^{P_i^0, P_{-i}^0} θ_i^0 ≥ W_{it}^{P_i, P_{-i}^0} θ_i^0` for any alternative policy `P_i ≠ P_i^0`
- Criterion function: `Q(θ, P^0) = Σ_{m,i,t} [min{0; W_{imt}^{P_i^0, P_{-i}^0} - W_{imt}^{P_i, P_{-i}^0} θ_i}]²`
- Notes that selection of alternative policies P is important choice for researcher

**Notebook**:
- Uses minimum distance: matches predicted probabilities `Φ((Λ - μ)/σ_μ)` to observed CCPs `d̂`
- Objective: `Σ [Φ((Λ - μ)/σ_μ) - d̂]² + Σ [Φ((Λ^E - γ)/σ_γ) - ê]²`
- This is equivalent to BBL approach but using probability matching rather than inequality violations

**Status**: ✓ **CONSISTENT** - notebook uses probability matching variant (as specified in homework), which is a valid alternative to moment inequalities

### 11.6 Multiple Equilibria ✓

**Chapter 4** (Section 2.2.4, lines 489-509):
- Notes that model generically has multiple equilibria
- Multiple equilibria possible when relaxing: (i) finite horizon, (ii) homogeneity, (iii) single firm investment per period
- Suggests testing with multiple initial guesses

**Notebook**:
- Tests for multiple equilibria with 5 different initial guesses (Question 5)
- Finds unique equilibrium (all guesses converge to same values)

**Status**: ✓ **CORRECT** - properly addresses multiplicity issue

### 11.7 Computational Considerations ✓

**Chapter 4** (Section 3.3.3, lines 2095-2101):
- Notes limitations: "number of possible forward paths can be greater than atoms in universe, but we use only a few million paths"
- "Approximations can be seriously biased, but we do not have practical way of knowing order of magnitude"
- Selection of alternative policies P can hide misspecification

**Notebook**:
- Uses R=50 simulations per state (reasonable for homework)
- Uses max_periods=100 (reasonable given β=0.9)
- Acknowledges these are approximations

**Status**: ✓ **APPROPRIATE** - uses reasonable simulation parameters, acknowledges approximation nature

### 11.8 Key Distinctions: BBL vs. Other Methods ✓

**Chapter 4** (Section 3.3.3, lines 1933-1945):
- BBL distinguishing features:
  1. Monte Carlo simulation to approximate present values
  2. Moment inequalities instead of pseudo-MLE/GMM/minimum distance
  3. Applicable to discrete or continuous decision/state variables

**Notebook**:
- ✓ Uses Monte Carlo forward simulation
- Uses minimum distance (not moment inequalities) - but this is homework specification
- ✓ Handles discrete states (N_t, x_t)

**Status**: ✓ **MOSTLY CONSISTENT** - notebook uses minimum distance variant (as specified in homework) rather than moment inequalities, but both are valid estimation approaches

---

## 12. Summary: Chapter 4 Validation ✓

### Overall Assessment: ✓ **VALIDATED**

The notebook implementation is **consistent with Chapter 4's comprehensive treatment**:

1. ✓ **MPNE Definition**: Correctly implements Markov Perfect Nash Equilibrium
2. ✓ **Incomplete Information**: Uses private information shocks to ensure equilibrium existence
3. ✓ **CCPs**: Properly estimates and uses conditional choice probabilities
4. ✓ **Integrated Value Function**: Correctly computes V̄ by integrating over private shocks
5. ✓ **BBL Forward Simulation**: Matches methodology described in Chapter 4
6. ✓ **Multiple Equilibria**: Tests for and addresses multiplicity issue
7. ✓ **Computational Approach**: Uses reasonable simulation parameters

### Note on Objective Function

The notebook uses **minimum distance** (matching probabilities) rather than **moment inequalities** as in the standard BBL method. However:
- This is **explicitly specified in the homework** (Question 9, Step F)
- Both approaches are valid estimation methods
- Probability matching is simpler and appropriate for this specific application
- Chapter 4 notes that BBL can be adapted with different objective functions

**Status**: ✓ **ACCEPTABLE** - follows homework specification, which is a valid variant of BBL approach

